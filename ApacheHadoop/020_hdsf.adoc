[[hdfs]]
== Hadoop file system

The Hadoop file system (HDSF) is a distributed file system. 
It uses an existing file system of the operating system but extends this with redundancy and distribution. 
HSDF hides the complexity of distributed storage and redundancy from the programmer. 

In the standard configuration HDFS saves all files three times on different nodes. 
The "name node" (server) has the information where the files are stored.  

Harddisks are very effective in reading large files sequentially but are much slower during random access. 
HDFS is therefore optimized for large files.  

To improve performance Hadoop also tries to move the computation to the nodes which store the data and not vice versa. 
Especially if you have very large data this helps to improve the performance as you can avoid that the network becomes the bottleneck. 

